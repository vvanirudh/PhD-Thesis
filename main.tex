\PassOptionsToPackage{svgnames,dvipsnames}{xcolor}

\documentclass[12pt]{cmuthesis}

\usepackage[Lenny]{fncychap}
\ChNameVar{\Large}

\input{packages}
\input{macros}

\draftstamp{\today}{DRAFT}

\begin {document}
\frontmatter

\pagestyle{empty}

\title{{\bf Planning and Execution using Inaccurate Models with
    Provable Guarantees on Task Completeness}}
\author{Anirudh Vemula}
\date{January 2022}
\Year{2022}
%\trnumber{CMU-CS-19-109}

\committee{
  Maxim Likhachev, Co-Chair \\
  J. Andrew Bagnell, Co-Chair \\
  Oliver Kroemer \\
  Leslie Pack Kaelbling (MIT)
%   \begin{tabular}{cc}
%     & \\
% Maxim Likhachev, Co-Chair & CMU\\
% J. Andrew Bagnell, Co-Chair & CMU\\
%     Oliver Kroemer & CMU \\
%     Leslie Pack Kaelbling & MIT
% \end{tabular}
}

\support{}
\disclaimer{}

\keywords{Robotics, Planning, Reinforcement Learning, Numerical Optimization}

\maketitle

\begin{dedication}
  For my brother, who put the fear of mediocrity in me \\
  For my mother, who sacrificed her own dreams to help me pursue
  mine \\
  For my love, who always believed in me and brought me back to surface
  when I sank to the depths
\end{dedication}

\begin{abstract}
  Modern planning methods are effective in computing feasible and
optimal plans for robotic tasks when given access to accurate
dynamical models.
However, robots operating in the real
world often face situations that cannot be modeled perfectly before
execution.
Thus, we only have access to simplified but potentially inaccurate 
models.
This imperfect modeling can lead to highly suboptimal plans
or even the inability to reach the goal during execution.
Existing approaches present a learning-based solution where real-world
experience is used to learn a complex dynamical model that is
subsequently used for planning. However, this requires a prohibitively
large amount of experience over the entire state space, and can
be wasteful if we are interested in completing the task and not in
modeling the dynamics accurately. Furthermore, real robots often have
operating constraints and cannot spend hours acquiring experience to
learn dynamics.
This thesis argues that by updating the behavior of the planner and
not the dynamics of the model, we can
leverage simplified and potentially inaccurate models and
significantly reduce the amount of real-world experience needed to
provably guarantee that the robot completes the task.

This thesis supports this argument from an algorithmic perspective
by presenting two novel algorithms.
The first algorithm \cmax{} guarantees that the robot reaches the
goal using the inaccurate model without any resets. This
is achieved by biasing the planner away from transitions whose
dynamics are discovered to be inaccurately modeled during online
execution. However, \cmax{} requires strong assumptions on the
accuracy of the model used for planning and fails to improve the
quality of solution over repetitions of the same task. The second
algorithm \cmaxpp{} leverages real-world experience to improve the
quality of resulting plans over successive repetitions of a robotic
task. \cmaxpp{} achieves this by integrating model-free learning using
acquired experience with model-based planning using the potentially
inaccurate model. As a consequence of this in addition to completeness, \cmaxpp{} also
guarantees asymptotic convergence to the optimal path cost
as the number of repetitions increases under relaxed
assumptions. Crucially, both algorithms do not require any updates to
the dynamics of the model unlike any existing method for planning
using inaccurate models.

From a theoretical perspective, this thesis presents a sample
complexity analysis of model-free methods and shows that their large
worst-case sample requirements make them not practical for robotic
tasks. Furthermore, we also present a performance analysis for methods
that leverage inaccurate models in linearized systems with
quadratic costs. Our analysis shows that naively using inaccurate
models can lead to large suboptimality gaps when modeling errors are
significant, while updating the behavior of the planner during
execution, like \cmax{} and \cmaxpp{}, can substantially reduce the
suboptimality gap. The thesis concludes by exploring the paradigm of
updating the dynamics of the model and presents an algorithm \taml{} that
directly optimizes task performance rather than prediction error. We
show that in the online setting where the 
robot does not have access to any resets, \taml{} outperforms prior
works that either optimize a maximum likelihood objective or rely on
an offline collected dataset with good coverage.

\end{abstract}

% \newgeometry{left=0.5in,right=0.5in,top=1in,bottom=1.4in}
% \begin{acknowledgments}
% \end{acknowledgments}
% \restoregeometry

\pagestyle{plain}

\tableofcontents
\addtocontents{toc}{\vspace*{-2cm}}
\listoffigures
\addtocontents{lof}{\vspace*{-2cm}}
\listoftables
\listofalgorithms

\mainmatter

\input{chapters/introduction}
\input{chapters/background}
%\input{chapters/related-work}
\input{chapters/aistats19}
\input{chapters/cmax}
\input{chapters/cmaxpp}
\input{chapters/ilc}
%\input{chapters/proposed-work}
\input{chapters/taml}
\input{chapters/future-work}
\input{chapters/appendix}

\chapter*{Bibliography}
\addcontentsline{toc}{chapter}{Bibliography}

\vspace{-25mm}
This bibliography contains \total{citenum} references.
\vspace{10mm}

\printbibliography[heading=none]

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
